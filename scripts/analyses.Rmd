---
title: "analyses"
author: "Alejandra Garcia Isaza"
date: "4/5/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rio)
library(here)
library(tidyverse)
library(haven)
library(janitor)
library(knitr)
library(surveytoolbox)
library(sjPlot)
library(kableExtra)
library(psych)
library(sjmisc)
library(MVN)

theme_set(theme_minimal())
```

# Loading the dataset
```{r}
d <- read_sav(here("data", "parent_hv1_youth_w1.sav"))
```

# only analysis variables

## id variables
school_id, condition, family_id, participant_id

## scales variables
- Structure at home (8)
select(q23_p1:q30_p1)

- School-Based Involvement (10)
select(q31_p1:q40_p1)

- Parent Belongingness in School (7)
select(q47_p1, q48_p1, q51_p1, q52_p1, q53_p1, q59_p1, q60_p1)

- Parent Endorsement of School (4)
select(q54_p1:q57_p1)

- Parent-Teacher Relationship (4) 
select(q64_p1:q67_p1)

- Parent-Child Conversations About School (14)
select(q68_p1:q81_p1)

- Homework Involvement (17)
select(q82_p1:q98_p1)

- Parent’s Value and Support of Education (6)
select(q105_p1:q110_p1)

- Appropriate Discipline (7)
select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1)

- Monitoring (5)
select(q137_p1, q139_p1, q140_p1, q143_p1, q144_p1)

- Family-School Communication (6)
select(q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1)

- Problem Solving with Educators (4)
select(q44_p1, q58_p1, q63_p1, q126_p1)

## outcome variable
- Students’ School Engagement (9)
select(q83_y1:q91_y1)

## moderators
- Ed level (1 - 11)
q36_hv1

- ENG comfort in youth school (1 - 5, 77, 99)
q173_3_p1

```{r}
d1 <- d %>%
  select(school_id, condition, family_id, participant_id, q23_p1:q30_p1, q31_p1:q40_p1, q47_p1, q48_p1, q51_p1, q52_p1, q53_p1, q59_p1, q60_p1, q54_p1:q57_p1, q64_p1:q67_p1, q68_p1:q81_p1, q82_p1:q98_p1, q105_p1:q110_p1, q128_p1:q131_p1, q133_p1, q134_p1, q136_p1, q137_p1, q139_p1, q140_p1, q143_p1, q144_p1, q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1, q44_p1, q58_p1, q63_p1, q126_p1, q36_hv1, q173_3_p1, q83_y1:q91_y1) # double check this, evaluate missing data 
```

# descriptives check 
```{r}
describe(d1)# using describe function I identified that missing values in the dataset were -99, 99, 77
```


# recoding missing variables as N/A
```{r include=FALSE}
# recoding missing values as N/A with function

# vector with missing values in dataset
missing_vals <- c(77, 99, -99)

# function that returns true if values in vector are equal to missing_vals. The function takes a vector x, and specified values of missing data
recode_missing <- function(x, missing_vals = c(77, 99, -99)) {
  test <- x %in% missing_vals
  ifelse(test, NA, x)
}

# function that recodes missing values to NA. The function takes a dataframe with variables with missing data, and specified values of missing data
recode_missing_df <- function(df, missing_vals = c(77, 99, -99)) {
  modify(df, ~recode_missing(.x, missing_vals)) # here uses the function created above
}

d2 <- recode_missing_df(d1) # the function strips out variable labels
```

# descriptives check #2 -- Evaluating missingness 
```{r}
describe(d2)
# using describe function I identified that some variables had a lot of missing information:
# q65_p1 = 89/94 responses ("En esta escuela,siento que hay por lo menos un maestro quien está interesado en conocerme")
# q173_3_p1 = 86/94 responses ("¿Qué tan cómodo/ase siente hablando inglés en la ESCUELA de su joven") --> moderator

(sum(is.na(d2))/prod(dim(d2)))*100 # 0.8450984 (this is less than 1% of the data, should I do something about it?)
# Nico's explanation:
#test <- describe(d2)
#(sum(94-test$n))/(94*107)
```

# Data prep: reverse scoring negatively worded items
```{r}
d3 <- d2 %>%
  mutate(q82_p1 = likert_reverse(q82_p1, top = 4, bottom = 1),
         q83_p1 = likert_reverse(q83_p1, top = 4, bottom = 1),
         q131_p1 = likert_reverse(q131_p1, top = 4, bottom = 1),
         q133_p1 = likert_reverse(q133_p1, top = 4, bottom = 1),
         q136_p1 = likert_reverse(q136_p1, top = 4, bottom = 1),
         q84_y1 = likert_reverse(q84_y1, top = 5, bottom = 1),
         q86_y1 = likert_reverse(q86_y1, top = 5, bottom = 1),
         q87_y1 = likert_reverse(q87_y1, top = 5, bottom = 1))
```

```{r}
# d3 %>%
#   haven::write_sav(here("data", "d3.sav"))
```

# dataset with only EFA variables 
```{r}
efa_vars <- d3 %>%
  select(-school_id, -condition, -family_id, -participant_id, -q36_hv1, -q173_3_p1)

describe(efa_vars)
```

# checking assumptions for pearson correlation model
"Departures from normality and linearity are important only because they affect the Pearson product-moment correlation coefficients (r) among measured variables used for computation of EFA results, which, in turn, “can result in misleading EFA findings” (Reise, Waller, & Comrey, 2000, p. 289). Therefore, it is important to investigate and report the distributional properties of the data that might affect the Pearson correlations (Goodwin & Leech, 2006)." (Watkins, 2018, p. 223).

- Variability
- linearity
- Normality (skew & kurtosis)
- Outliers
- Measurement error: variables with reliabilities > .70 (which computation?)
- Correlation matrix: sizable number of correlations should exceed ±.30 

## using pearson correlation 
- skew & kurtosis: inside the range of -2 to 2 (-2,-1,0,1,2)
- then, look at those variables that appear to be problematic
- then look the bar graph for those problematic variables
- run EFA with them, run without them -- sensitivity analysis    -- (if still indicates the same # of factors, decide if            leaving or keeping)

## Inspecting normality

# checking for out of range kurtosis & skew variables
```{r}
efa_vars_desc <- data.frame(describe(efa_vars))

efa_vars_desc %>%
  filter(kurtosis < -2 | kurtosis > 2)

efa_vars_desc %>%
  filter(skew < -2 | skew > 2) # these are included above
```

q74_p1 -- "En los últimos tres meses, ¿con qué frecuencia usted ha tenido una conversación con su joven sobre cómo va en sus clases."
1 = Nunca, 2 = Raramente, 3 = A veces, 4 = A menudo.
skew: -2.99
kurtosis: 10.57

# function to visualize all variables in the dataset
code taken from: https://stackoverflow.com/questions/52822840/ggplot2-create-a-barplot-for-every-column-of-a-dataframe 

```{r}
plots_all <- split.default(efa_vars, names(efa_vars)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })
```

# Multivariate and univariate normality tests on all variables
```{r}
mvn(efa_vars, subset = NULL, mvnTest = "hz", univariateTest = "AD") # mvn uses listwise deletion for missing data

# conclusion: none of the variables meet the normality assumption based on Anderson-Darling test
```

# Multivariate and univariate normality tests by scale: 
```{r}
#Structure at home (8)
scale_1 <- efa_vars %>%
  select(q23_p1:q30_p1)

mvn(scale_1, subset = NULL, mvnTest = "hz", univariateTest = "AD", univariatePlot = "histogram") # mvn uses listwise deletion for missing data
```

```{r}
# School-based involvement (10)
scale_2 <- efa_vars %>%
  select(q31_p1:q40_p1)

mvn(scale_2, subset = NULL, mvnTest = "hz", univariateTest = "AD", univariatePlot = "histogram", showOutliers = TRUE) # mvn uses listwise deletion for missing data

describe(scale_2)
```

```{r}
# Parent Belongingness in School (7)
scale_3 <- efa_vars %>%
  select(q47_p1, q48_p1, q51_p1, q52_p1, q53_p1, q59_p1, q60_p1)

mvn(scale_3, subset = NULL, mvnTest = "hz", univariateTest = "AD", univariatePlot = "histogram") # mvn uses listwise deletion for missing data

describe(scale_3)
```

```{r}
# Parent Endorsement of School (4)
scale_4 <- efa_vars %>%
  select(q54_p1:q57_p1)

mvn(scale_4, subset = NULL, mvnTest = "hz", univariateTest = "AD", univariatePlot = "histogram")

describe(scale_4)
```

```{r}
plots <- split.default(scale_4, names(scale_4)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots
```


# issue of sparseness
```{r}
#contingency tables? 
```


--------------------------
## EFA decisions 
--------------------------

# Homework Involvement (17)
```{r}
# Homework Involvement (17)
scale_7 <- efa_vars %>%
  select(q82_p1:q98_p1)

# Poly corr matrix
poly_scale_7 <- polychoric(scale_7)
poly_scale_7_mat <- data.frame(poly_scale_7$rho)

# scree plot
scree(poly_scale_7_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_7, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
#removing 82, 83, 92
scale_7.1 <- efa_vars %>%
  select(q84_p1:q91_p1, q93_p1:q98_p1)

# PARALLEL ANALYSIS - Homework Involvement (17)
fa.parallel(scale_7.1, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # parrallel analysis suggest 4 factors

# 4 factors
fa(scale_7.1, nfactors = 4, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly")

# 3 factors
fa(scale_7.1, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly")
```

```{r}
#Reliability: Homework Involvement (17)
scale_7.1_fa_1 <- efa_vars %>%
  select(q86_p1:q89_p1, q94_p1, q96_p1, q97_p1)

alpha(scale_7.1_fa_1) # 0.78

scale_7.1_fa_2 <- efa_vars %>%
  select(q84_p1, q85_p1, q93_p1, q95_p1)

alpha(scale_7.1_fa_2) # 0.70 (0.77 if removing 95)

scale_7.1_fa_3 <- efa_vars %>%
  select(q90_p1, q91_p1, q98_p1) 

alpha(scale_7.1_fa_3) # 0.59
```

# Monitoring (5)
```{r}
#Monitoring (5)
scale_10 <- efa_vars %>%
  select(q137_p1, q139_p1, q140_p1, q143_p1, q144_p1)

# Poly corr matrix
poly_scale_10 <- polychoric(scale_10)
poly_scale_10_mat <- data.frame(poly_scale_10$rho)

# scree plot
scree(poly_scale_10_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_10, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
#Reliability: Monitoring (5)

alpha(scale_10) # 0.62
```

# Appropriate Discipline (7) <<<<< ultra-Heywood case>>>>>>>
```{r}
#Appropriate Discipline (7)
scale_9 <- efa_vars %>%
  select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1)

# Poly corr matrix
poly_scale_9 <- polychoric(scale_9)
poly_scale_9_mat <- data.frame(poly_scale_9$rho)

# scree plot
scree(poly_scale_9_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_9, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
# Appropriate Discipline EFA iterations 

# iteration 1
scale_9.1 <- efa_vars %>%
  select(q129_p1:q131_p1, q133_p1, q134_p1, q136_p1)

fa(scale_9.1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # item 129 now appears as heywood

# iteration 2
scale_9.2 <- efa_vars %>%
  select(q130_p1, q131_p1, q133_p1, q134_p1, q136_p1)

fa(scale_9.2, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # no more heywood

poly_scale_9.2 <- polychoric(scale_9.2)
poly_scale_9.2_mat <- data.frame(poly_scale_9.2$rho)

# scree plot
scree(poly_scale_9.2_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# PARALLEL ANALYSIS - Appropriate discipline (7)
fa.parallel(scale_9.2, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5)

# 2 factors (JUST TO CHECK)
# fa(scale_9.2, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # first factor made of just one item and heywood case

# iteration 3
scale_9.3 <- efa_vars %>%
  select(q131_p1, q133_p1, q136_p1)

fa(scale_9.3, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
# Appropriate Discipline reliability 
scale_9.3 <- efa_vars %>%
  select(q131_p1, q133_p1, q136_p1)

alpha(scale_9.3) # 0.50 NOT GOOD

# just to check alpha with the 5 items:
scale_9.2 <- efa_vars %>%
  select(q130_p1, q131_p1, q133_p1, q134_p1, q136_p1)

alpha(scale_9.2) # 0.41 even worse! 
```

```{r}
#Appropriate Discipline univariate analysis

d2 %>% #before reverse scoring
  select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1) %>%
  mutate(q128_p1 = as.factor(q128_p1),
         q129_p1 = as.factor(q129_p1),
         q130_p1 = as.factor(q130_p1),
         q131_p1 = as.factor(q131_p1),# no one fully endorsed yelling
         q133_p1 = as.factor(q133_p1),# 4 endorsed quiting 
         q134_p1 = as.factor(q134_p1),#8 endorsed not following
         q136_p1 = as.factor(q136_p1)) %>%
  summary()
```

```{r}
#Appropriate Discipline univariate analysis

efa_vars %>% #after reverse scoring
  select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1) %>%
  mutate(q128_p1 = as.factor(q128_p1),
         q129_p1 = as.factor(q129_p1),
         q130_p1 = as.factor(q130_p1),
         q131_p1 = as.factor(q131_p1),
         q133_p1 = as.factor(q133_p1),
         q134_p1 = as.factor(q134_p1),
         q136_p1 = as.factor(q136_p1)) %>%
  summary()

```


# Structure at home (8)
```{r}
# Structure at home (8)
scale_1 <- efa_vars %>%
  select(q23_p1:q30_p1)

# Poly corr matrix
poly_scale_1 <- polychoric(scale_1)
poly_scale_1_mat <- data.frame(poly_scale_1$rho)

# scree plot
scree(poly_scale_1_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly", sort = TRUE)
```


```{r}
#Reliability: Structure at home (8)

alpha(scale_1) # 0.82
```

# Parent-Child Conversations About School (14)
```{r}
#Parent-Child Conversations About School (14)
scale_6 <- efa_vars %>%
  select(q68_p1:q81_p1)

# Poly corr matrix
poly_scale_6 <- polychoric(scale_6)
poly_scale_6_mat <- data.frame(poly_scale_6$rho)

# scree plot
scree(poly_scale_6_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_6, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
# PARALLEL ANALYSIS Parent-Child Conversations
fa.parallel(scale_6, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # parrallel analysis suggest 3 factors

# 3 factors
fa(scale_6, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # item 74 cross loaded in factor 1 and 2

# iteration 1
scale_6.1 <- efa_vars %>%
  select(q68_p1:q73_p1, q75_p1:q81_p1)

# 3 factors - # iteration 1
fa(scale_6.1, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # item 72 cross loaded in factor 2 and 3

# iteration 2
scale_6.2 <- efa_vars %>%
  select(q68_p1:q71_p1, q73_p1, q75_p1:q81_p1)

# 3 factors - # iteration 2
fa(scale_6.2, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") 
```

```{r}
#Reliability: Parent-Child Conversations About School (14)

#factor 3
scale_6.fa_3 <- efa_vars %>%
  select(q68_p1:q71_p1)

alpha(scale_6.fa_3) # 0.81

#factor 2
scale_6.fa_2 <- efa_vars %>%
  select(q73_p1, q75_p1, q80_p1, q81_p1)

alpha(scale_6.fa_2) # 0.78

#factor 1
scale_6.fa_1 <- efa_vars %>%
  select(q76_p1:q79_p1) 

alpha(scale_6.fa_1) # 0.85
```

# School-based involvement (10)
```{r}
# School-based involvement (10)
scale_2 <- efa_vars %>%
  select(q31_p1:q40_p1)

# Poly corr matrix
poly_scale_2 <- polychoric(scale_2)
poly_scale_2_mat <- data.frame(poly_scale_2$rho)

# scree plot
scree(poly_scale_2_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE) # a little ambiguous

# EFA
fa(scale_2, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
# PARALLEL ANALYSIS School-based involvement 
fa.parallel(scale_2, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5)
# suggests 3 factors, but a warning about ultra heywood case

# 3 factors
fa(scale_2, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # factor 3 barely above eigenvalue >1 and crossloading items

# 2 factors
fa(scale_2, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # q35_p1 cross-loaded


scale_2.1 <- efa_vars %>%
  select(q31_p1:q34_p1, q36_p1:q40_p1)

# 2 factors
fa(scale_2.1, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly")
```

```{r}
#Reliability: School-based involvement 
scale_2.1_fa_1 <- efa_vars %>%
  select(q31_p1:q34_p1)

alpha(scale_2.1_fa_1) # 0.85

scale_2.1_fa_2 <- efa_vars %>%
  select(q36_p1:q40_p1)

alpha(scale_2.1_fa_2) # 0.82
```


##### Relational approach #####

# Parent Belongingness in School (7)
```{r}
# Parent Belongingness in School (7)
scale_3 <- efa_vars %>%
  select(q47_p1, q48_p1, q51_p1, q52_p1, q53_p1, q59_p1, q60_p1)

# Poly corr matrix
poly_scale_3 <- polychoric(scale_3)
poly_scale_3_mat <- data.frame(poly_scale_3$rho)

# scree plot
scree(poly_scale_3_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_3, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")

alpha(scale_3) #0.82
```


```{r}
fa.parallel(scale_3, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # parallel analysis suggest 3 factors

# 2 FACTORS
fa(scale_3, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # one factor with 2 items bc one item is crossloading
```


```{r}
#alternative proposal Parent Belongingness in School (4)(makes more sense conceptually):
scale_3.1 <- efa_vars %>%
  select(q47_p1, q48_p1, q51_p1, q52_p1, q53_p1)

# Poly corr matrix
poly_scale_3.1 <- polychoric(scale_3.1)
poly_scale_3.1_mat <- data.frame(poly_scale_3.1$rho)

# scree plot
scree(poly_scale_3.1_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_3.1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
#reliability parent Belongingness in School (5)
alpha(scale_3.1) # 0.72
```


# Parent Endorsement of School (4) <<< ultra-Heywood case>>>
```{r}
# Parent Endorsement of School (4)
scale_4 <- efa_vars %>%
  select(q54_p1:q57_p1)

# Poly corr matrix
poly_scale_4 <- polychoric(scale_4)
poly_scale_4_mat <- data.frame(poly_scale_4$rho)

# scree plot
scree(poly_scale_4_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA 
fa(scale_4, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
#alternative proposal Parent endorsement of School (7)(makes more sense face value):
scale_4.1 <- efa_vars %>%
  select(q52_p1, q54_p1:q57_p1, q59_p1, q60_p1)

# Poly corr matrix
poly_scale_4.1 <- polychoric(scale_4.1)
poly_scale_4.1_mat <- data.frame(poly_scale_4.1$rho)

# scree plot
scree(poly_scale_4.1_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_4.1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # no heywood, but now says matrix non-positive defintive which I guess is improvement (?)

fa.parallel(scale_4.1, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # parrallel analysis suggest 2 factors

# 2 factors
fa(scale_4.1, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # 
```

see univariate and check what is the percenatge of responses in each case to provide argumnet that variables are not "varying"
think in discussion which had a really strong factor solution with large variance explained and will i recommend dropping or imporving the measures 

"This outcome highlights the general concern of sparseness, or the tendency of highly skewed items to produce observed bivariate distributions with cell frequencies equaling zero or close to zero,especially with relatively small overall sample size. Sparseness can cause biased polychoric correlation estimates, which in turn leads to inaccurate factor
analysis results" (Flora et al. 2012, p. 18)

```{r}
scale_4 %>%
  mutate(q54_p1 = as.factor(q54_p1),
         q55_p1 = as.factor(q55_p1),
         q56_p1 = as.factor(q56_p1),
         q57_p1 = as.factor(q57_p1)) %>%
  summary()
```

```{r}
### -----Parent Endorsement of School (4)----- ###

# EFA without q55_p1 = bec it had a negative u2 and a factor loading of 1
scale_4.1 <- efa_vars %>%
  select(q54_p1, q56_p1, q57_p1)

fa(scale_4.1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")

scree(scale_4.1,factors=TRUE,pc=FALSE,main="Scree plt",hline=NULL,add=FALSE)

```

# Parent-Teacher Relationship (4) <<< ultra-Heywood case>>>
```{r}
# Parent-Teacher Relationship (4) 
scale_5 <- efa_vars %>%
  select(q64_p1:q67_p1)

# Poly corr matrix
poly_scale_5 <- polychoric(scale_5)
poly_scale_5_mat <- data.frame(poly_scale_5$rho)

# scree plot
scree(poly_scale_5_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_5, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
### -----Parent-Teacher Relationship (4) ----- ###

# EFA without q66_p1 = bec it had a negative u2 and a factor loading of 1
scale_4.1 <- efa_vars %>%
  select(q64_p1, q65_p1, q67_p1)

fa(scale_4.1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")

scree(scale_4.1,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA without q67_p1 = bec it had a factor loading of 0.99
scale_4.2 <- efa_vars %>%
  select(q64_p1, q65_p1) # not reasonable a 2 item scale

fa(scale_4.2, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")

scree(scale_4.2,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)
```


# Family-School Communication (6)
```{r}
#Family-School Communication (6)
scale_11 <- efa_vars %>%
  select(q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1)

# Poly corr matrix
poly_scale_11 <- polychoric(scale_11)
poly_scale_11_mat <- data.frame(poly_scale_11$rho)

# scree plot
scree(poly_scale_11_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_11, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```


--------------------
EFA COMBINING PARENT ENDORSEMENT, PARENT-TEACH REL, AND FAMILY-SCHOOL COMMUNICATION. 
q54_p1:q57_p1 --> parent endorsement
q59_p1, q60_p1 --> extra from belong 
q64_p1:q67_p1 --> parent-teacher rel
q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1 --> communication

```{r}
test_scale <- efa_vars %>%
  select(q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q54_p1, q55_p1, q56_p1, q57_p1, q59_p1, q60_p1, q62_p1, q64_p1, q65_p1, q66_p1, q67_p1)

# Poly corr matrix
poly_test_scale <- polychoric(test_scale)
poly_test_scale_mat <- data.frame(poly_test_scale$rho)

# scree plot
scree(poly_test_scale_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(test_scale, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # says matrix not positive definite

# ITERATION 1
test_scale1 <- efa_vars %>%
  select(q41_p1, q43_p1, q50_p1, q54_p1, q55_p1, q56_p1, q57_p1, q59_p1, q60_p1, q62_p1, q64_p1, q65_p1, q66_p1, q67_p1) # removing 18 and 19 because loading less than .30

# EFA ITERATION 1
fa(test_scale1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # says matrix not positive definite
```

```{r}
fa.parallel(test_scale1, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # parallel analysis suggest 3 factors, matrix not positive, ultra heywood detected

# 3 factors
fa(test_scale1, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # says matrix not positive & ultra heywood: item 66 negative u2

# ITERATION 2
test_scale2 <- efa_vars %>%
  select(q41_p1, q43_p1, q50_p1, q54_p1, q55_p1, q56_p1, q57_p1, q59_p1, q60_p1, q62_p1, q64_p1, q65_p1, q67_p1) # removing item 66 with ultra heywood

# 3 factors (without 66) - ITERATION 2
fa(test_scale2, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # now just matrix not positive definite warning; crossloading item 64

# ITERATION 3
test_scale3 <- efa_vars %>%
  select(q41_p1, q43_p1, q50_p1, q54_p1, q55_p1, q56_p1, q57_p1, q59_p1, q60_p1, q62_p1, q65_p1, q67_p1) # removing crossloading item 64

# 3 factors (without 64) - # ITERATION 3
fa(test_scale3, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # now just matrix not positive definite warning; crossloading item 59

# ITERATION 4
test_scale4 <- efa_vars %>%
  select(q41_p1, q43_p1, q50_p1, q54_p1, q55_p1, q56_p1, q57_p1, q60_p1, q62_p1, q65_p1, q67_p1) # removing crossloading item 64

# 3 factors (without 59) - # ITERATION 4
fa(test_scale4, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # now just matrix not positive definite warning
```


```{r}
#reliabilities on iteration 4

# factor 1 yellow (4 items)
test_scale4_fa1 <- efa_vars %>%
  select(q55_p1, q56_p1, q57_p1, q62_p1)

alpha(test_scale4_fa1) #.91

# factor 2 blue (4 items)
test_scale4_fa2 <- efa_vars %>%
  select(q43_p1, q50_p1, q54_p1, q60_p1)

alpha(test_scale4_fa2) #.84

# factor 3 green (3 items)
test_scale4_fa3 <- efa_vars %>%
  select(q41_p1, q65_p1, q67_p1)

alpha(test_scale4_fa3) #.75
```

--------------------

# Problem Solving with Educators (4)
```{r}
#Problem Solving with Educators (4)
scale_12 <- efa_vars %>%
  select(q44_p1, q58_p1, q63_p1, q126_p1)

# Poly corr matrix
poly_scale_12 <- polychoric(scale_12)
poly_scale_12_mat <- data.frame(poly_scale_12$rho)

# scree plot
scree(poly_scale_12_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_12, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
#Problem Solving with Educators (4) 
fa.parallel(scale_12, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # suggest 2 factors, but one appears to be an eigenvalue less than 1

# EFA 2 factors
fa(scale_12, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # with 2 factors shows ultra-heywood case, also would be each factor with just 2 items
```


```{r}
#Reliability: Problem Solving with Educators (4) 

alpha(scale_12) # 0.71; if removing items 126 would be .79
```

# Parent’s Value and Support of Education (6) <<<#matrix not positive definitive>>>
```{r}
#Parent’s Value and Support of Education (6)
scale_8 <- efa_vars %>%
  select(q105_p1:q110_p1)

# Poly corr matrix
poly_scale_8 <- polychoric(scale_8)
poly_scale_8_mat <- data.frame(poly_scale_8$rho)

# scree plot
scree(poly_scale_8_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_8, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```
```{r}
#Parent’s Value and Support of Education (6)
fa.parallel(scale_8, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # suggest 1 factor

```

```{r}
# RELIABILITY Parent’s Value and Support of Education (6)

alpha(scale_8) # .91

scale_8 %>%
  mutate(q105_p1 = as.factor(q105_p1),
         q106_p1 = as.factor(q106_p1),
         q107_p1 = as.factor(q107_p1),
         q108_p1 = as.factor(q108_p1),
         q109_p1 = as.factor(q109_p1),
         q110_p1 = as.factor(q110_p1)) %>%
  summary()
```

```{r}
# Parent’s Value and Support of Education (6)
plots3 <- split.default(scale_8, names(scale_8)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots3
```

# OUTCOME: Students’ School Engagement (9)
```{r}
#Students’ School Engagement (9)
scale_13 <- efa_vars %>%
  select(q83_y1:q91_y1)

# Poly corr matrix
poly_scale_13 <- polychoric(scale_13)
poly_scale_13_mat <- data.frame(poly_scale_13$rho)

# scree plot
scree(poly_scale_13_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_13, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

-------------------------------------------------
Excerpts
-------------------------------------------------
Determining the number of factors in EFA:

"A number of analytical processes have been used to determine
the number of factors to retain from a list of items, and it is
beyond the scope of this paper to describe all of them. For
scale development, commonly available methods to determine
the number of factors to retain include a scree plot (85), the
variance explained by the factor model, and the pattern of factor loadings (2). Where feasible, researchers could also assess the optimal number of factors to be drawn fromthe list of items using either parallel analysis (86), minimum average partial procedure (87), or the Hull method (88, 89)." (Boateng et al., 2018)

DD also suggested parallewl analysis... Maybe use it when in doubt? For HW involvement? 

---------------------------------------------
Psych package info:
" For those who like SPSS type output, the measure of factoring adequacy known as the Kaiser-Meyer-Olkin KMO test may be found from the correlation matrix or data matrix using the KMO function. Similarly, the Bartlett’s test of Sphericity may be found using the cortest.bartlett function"


Model fit indices:

"RMSEA is an absolute fit index, in that it assesses how far a hypothesized model is from a perfect model. On the contrary, CFI and TLI are incremental fit indices that compare the fit of a hypothesized model with that of a baseline model (i.e., a model with the worst fit)" (Xia & Yang, p. 309)

Hu and Bentler (1999) suggested relatively good model–data fit:
RMSEA smaller than .06 
CFI and TLI larger than .95 

But these estimates are for continuous data, using normal-theory maximum likelihood (ML). 

Conclusion from (Xia & Yang, p. 421)
"Given that the DWLS and ULS fit indices tend to show a better model–data fit evaluation than do ML fit indices when the same misspecified model is analyzed, we argue that surpassing a set of cutoff values should not serve as the only justification for the acceptance of a model. It would be more appropriate to consider RMSEA, CFI, and TLI as diagnostic tools for model improvement." 

-----
alpha internal consistencies benchmarks
.00 to .69 = Poor reliability  
.70 to .79 = Fair reliability  
.80 to .89 = Good reliability  
.90 to .99 = Excellent/Strong reliability  

---- Qs ----
Q: Are model fit indices used in EFA? Still not super clear. DD said will send some info.

reliability --- alpha -- can be done with ordinal scales?

DD: polychoric may be robust to non-normality


test to look at input hsquared


for heywood cases, say that porb measures are suspect and may need to be improved

######### EXPLORING UNIVARIATE IN HEYWOOD CASES ##############

Endorsement:

Como madre/padre en esta escuela, estoy segura/o de que…

54. … esta escuela es un buen lugar para mi joven. 
56. … la gente en la escuela de mi joven es confiable.
57. … la escuela de mi joven hace un buen trabajo preparando a      los jóvenes para sus futuros.

59. … los maestros de mi joven se preocupan por ella/el.
60. … maestros y administradores trabajan juntos para crear un ambiente seguro y acogedor para todos.

52. …feliz de que mi joven asista a esta escuela.

-------
55. … el personal de la escuela de mi joven está haciendo     cosas buenas por ella/el.
-------


En esta escuela, siento que hay por lo menos un maestro…
64. … que se preocupa por mi joven.
65. … quien está interesado en conocerme.

---------
66. … con quien me siento/a cómodo/a hablando sobre mi joven.
67. … de quien puedo hacer preguntas o hacer sugerencias sobre mi joven.
---------

#ultra-Heywood case
Como madre/padre en esta escuela, estoy segura/o de que…
54. … esta escuela es un buen lugar para mi joven. 
55. … el personal de la escuela de mi joven está haciendo cosas buenas por ella/el.*
56. … la gente en la escuela de mi joven es confiable.
57. … la escuela de mi joven hace un buen trabajo preparando a los jóvenes para sus futuros.

```{r}
# Parent Endorsement of School (4)
scale_4 <- efa_vars %>%
  select(q54_p1:q57_p1)

scale_4 %>%
  mutate(q54_p1 = as.factor(q54_p1),
         q55_p1 = as.factor(q55_p1),
         q56_p1 = as.factor(q56_p1),
         q57_p1 = as.factor(q57_p1)) %>%
  summary()
```

```{r}
plots <- split.default(scale_4, names(scale_4)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots
```

#ultra-Heywood case
En esta escuela, siento que hay por lo menos un maestro…
64. … que se preocupa por mi joven.
65. … quien está interesado en conocerme.
66. … con quien me siento/a cómodo/a hablando sobre mi joven.*
67. … de quien puedo hacer preguntas o hacer sugerencias sobre mi joven.*

```{r}
# Parent-Teacher Relationship (4) 
scale_5 <- efa_vars %>%
  select(q64_p1:q67_p1)

scale_5 %>%
  mutate(q64_p1 = as.factor(q64_p1),
         q65_p1 = as.factor(q65_p1),
         q66_p1 = as.factor(q66_p1),
         q67_p1 = as.factor(q67_p1)) %>%
  summary()
```

```{r}
plots2 <- split.default(scale_5, names(scale_5)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots2
```


#ultra-Heywood case

128. En casa, estamos de acuerdo con reglas claras sobre lo que mi joven puede y no puede hacer.
129. Mi joven sabe cómo voy a responder cuando hace algo malo cosas que no me gustan o lo que está en contra las reglas de la casa).
130. Cada vez que mi joven hace algo mal, yo le respondo con una consecuencia específica (por ejemplo, una disciplina específica, quitándole      privilegios, etc.)
131. Cuando mi joven hace algo mal, le grito o le insulto. R
133. Cuando mi joven me desafía al no hacer lo que le pido, yo renuncio. R
134. Cuando mi joven está aprendiendo un nuevo comportamiento (por ejemplo: ser más responsable, estudioso/a u organizado/a), reconozco su        progreso con, por ejemplo, un abrazo, una sonrisa o un pequeño regalo.
136. Cuando le doy una amenaza o advertencia a mi joven, frecuentemente no lo llevo a cabo. R

```{r}
#Appropriate Discipline (7)
scale_9 <- efa_vars %>%
  select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1)

scale_9 %>%
  mutate(q128_p1 = as.factor(q128_p1),
         q129_p1 = as.factor(q129_p1),
         q130_p1 = as.factor(q130_p1),
         q131_p1 = as.factor(q131_p1),
         q133_p1 = as.factor(q133_p1),
         q134_p1 = as.factor(q134_p1),
         q136_p1 = as.factor(q136_p1)) %>%
  summary()
```

```{r}
plots4 <- split.default(scale_9, names(scale_9)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots4
```
