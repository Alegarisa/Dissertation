---
title: "analyses"
author: "Alejandra Garcia Isaza"
date: "4/5/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rio)
library(here)
library(tidyverse)
library(haven)
library(janitor)
library(knitr)
library(surveytoolbox)
library(sjPlot)
library(kableExtra)
library(psych)
library(sjmisc)
library(MVN)

theme_set(theme_minimal())
```

# Loading the dataset
```{r}
d <- read_sav(here("data", "parent_hv1_youth_w1.sav"))
```

# only analysis variables

## id variables
school_id, condition, family_id, participant_id

## scales variables
- Structure at home (8)
select(q23_p1:q30_p1)

- School-Based Involvement (10)
select(q31_p1:q40_p1)

- Parent Belongingness in School (7)
select(q47_p1, q48_p1, q51_p1, q52_p1, q53_p1) # DELETED items 59 & 60

- Parent Endorsement of School (4)
select(q54_p1:q57_p1)

- Parent-Teacher Relationship (4) 
select(q64_p1:q67_p1)

- Parent-Child Conversations About School (14)
select(q68_p1:q81_p1)

- Homework Involvement (17)
select(q82_p1:q98_p1)

- Parent’s Value and Support of Education (6)
select(q105_p1:q110_p1)

- Appropriate Discipline (7)
select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1)

- Monitoring (5)
select(q137_p1, q139_p1, q140_p1, q143_p1, q144_p1)

- Family-School Communication (6)
select(q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1)

- Problem Solving with Educators (4)
select(q44_p1, q58_p1, q63_p1, q126_p1)

## outcome variable
- Students’ School Engagement (9)
select(q83_y1:q91_y1)

## moderators
- Ed level (1 - 11)
q36_hv1

- ENG comfort in youth school (1 - 5, 77, 99)
q173_3_p1

```{r}
d1 <- d %>%
  select(school_id, condition, family_id, participant_id, q23_p1:q30_p1, q31_p1:q40_p1, q47_p1, q48_p1, q51_p1, q52_p1, q53_p1, q59_p1, q60_p1, q54_p1:q57_p1, q64_p1:q67_p1, q68_p1:q81_p1, q82_p1:q98_p1, q105_p1:q110_p1, q128_p1:q131_p1, q133_p1, q134_p1, q136_p1, q137_p1, q139_p1, q140_p1, q143_p1, q144_p1, q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1, q44_p1, q58_p1, q63_p1, q126_p1, q36_hv1, q173_3_p1, q83_y1:q91_y1) # double check this, evaluate missing data 
```

# descriptives check 
```{r}
# describe(d1)# using describe function I identified that missing values in the dataset were -99, 99, 77
```


# recoding missing variables as N/A
```{r include=FALSE}
# recoding missing values as N/A with function

# vector with missing values in dataset
missing_vals <- c(77, 99, -99)

# function that returns true if values in vector are equal to missing_vals. The function takes a vector x, and specified values of missing data
recode_missing <- function(x, missing_vals = c(77, 99, -99)) {
  test <- x %in% missing_vals
  ifelse(test, NA, x)
}

# function that recodes missing values to NA. The function takes a dataframe with variables with missing data, and specified values of missing data
recode_missing_df <- function(df, missing_vals = c(77, 99, -99)) {
  modify(df, ~recode_missing(.x, missing_vals)) # here uses the function created above
}

d2 <- recode_missing_df(d1) # the function strips out variable labels
```

# descriptives check #2 -- Evaluating missingness 
```{r}
#describe(d2)
# using describe function I identified that some variables had a lot of missing information:
# q65_p1 = 89/94 responses ("En esta escuela,siento que hay por lo menos un maestro quien está interesado en conocerme")
# q173_3_p1 = 86/94 responses ("¿Qué tan cómodo/ase siente hablando inglés en la ESCUELA de su joven") --> moderator

#(sum(is.na(d2))/prod(dim(d2)))*100 # 0.8450984 (this is less than 1% of the data, should I do something about it?)
# Nico's explanation:
#test <- describe(d2)
#(sum(94-test$n))/(94*107)
```

# Data prep: reverse scoring negatively worded items
```{r}
d3 <- d2 %>%
  mutate(q82_p1 = likert_reverse(q82_p1, top = 4, bottom = 1),
         q83_p1 = likert_reverse(q83_p1, top = 4, bottom = 1),
         q131_p1 = likert_reverse(q131_p1, top = 4, bottom = 1),
         q133_p1 = likert_reverse(q133_p1, top = 4, bottom = 1),
         q136_p1 = likert_reverse(q136_p1, top = 4, bottom = 1),
         q84_y1 = likert_reverse(q84_y1, top = 5, bottom = 1),
         q86_y1 = likert_reverse(q86_y1, top = 5, bottom = 1),
         q87_y1 = likert_reverse(q87_y1, top = 5, bottom = 1))
```

```{r}
# d3 %>%
#   haven::write_sav(here("data", "d3.sav"))
```

# dataset with only EFA variables 
```{r}
efa_vars <- d3 %>%
  select(-school_id, -condition, -family_id, -participant_id, -q36_hv1, -q173_3_p1)

describe(efa_vars)
```

# checking assumptions for pearson correlation model
"Departures from normality and linearity are important only because they affect the Pearson product-moment correlation coefficients (r) among measured variables used for computation of EFA results, which, in turn, “can result in misleading EFA findings” (Reise, Waller, & Comrey, 2000, p. 289). Therefore, it is important to investigate and report the distributional properties of the data that might affect the Pearson correlations (Goodwin & Leech, 2006)." (Watkins, 2018, p. 223).

- Variability
- linearity
- Normality (skew & kurtosis)
- Outliers
- Measurement error: variables with reliabilities > .70 (which computation?)
- Correlation matrix: sizable number of correlations should exceed ±.30 

## using pearson correlation 
- skew & kurtosis: inside the range of -2 to 2 (-2,-1,0,1,2)
- then, look at those variables that appear to be problematic
- then look the bar graph for those problematic variables
- run EFA with them, run without them -- sensitivity analysis    -- (if still indicates the same # of factors, decide if            leaving or keeping)

## Inspecting normality

# checking for out of range kurtosis & skew variables
```{r}
efa_vars_desc <- data.frame(describe(efa_vars))

efa_vars_desc %>%
  filter(kurtosis < -2 | kurtosis > 2)

efa_vars_desc %>%
  filter(skew < -2 | skew > 2) # these are included above
```

q74_p1 -- "En los últimos tres meses, ¿con qué frecuencia usted ha tenido una conversación con su joven sobre cómo va en sus clases."
1 = Nunca, 2 = Raramente, 3 = A veces, 4 = A menudo.
skew: -2.99
kurtosis: 10.57

# function to visualize all variables in the dataset
code taken from: https://stackoverflow.com/questions/52822840/ggplot2-create-a-barplot-for-every-column-of-a-dataframe 

```{r}
# plots_all <- split.default(efa_vars, names(efa_vars)) %>% 
#   map(., setNames, nm = "var") %>% 
#   map(., rownames_to_column) %>%
#   imap(., ~ {
#     ggplot(.x, aes(var)) + 
#       geom_bar() +
#       labs(title = .y)
#     })
```

# Multivariate and univariate normality tests on all variables
```{r}
mvn(efa_vars, subset = NULL, mvnTest = "hz", univariateTest = "AD") # mvn uses listwise deletion for missing data

# conclusion: none of the variables meet the normality assumption based on Anderson-Darling test
```

# Multivariate and univariate normality tests by scale: 
```{r}
#Structure at home (8)
scale_1 <- efa_vars %>%
  select(q23_p1:q30_p1)

mvn(scale_1, subset = NULL, mvnTest = "hz", univariateTest = "AD", univariatePlot = "histogram") # mvn uses listwise deletion for missing data
```

```{r}
# School-based involvement (10)
scale_2 <- efa_vars %>%
  select(q31_p1:q40_p1)

mvn(scale_2, subset = NULL, mvnTest = "hz", univariateTest = "AD", univariatePlot = "histogram", showOutliers = TRUE) # mvn uses listwise deletion for missing data

describe(scale_2)
```

```{r}
# Parent Belongingness in School (7)
scale_3 <- efa_vars %>%
  select(q47_p1, q48_p1, q51_p1, q52_p1, q53_p1, q59_p1, q60_p1)

mvn(scale_3, subset = NULL, mvnTest = "hz", univariateTest = "AD", univariatePlot = "histogram") # mvn uses listwise deletion for missing data

describe(scale_3)
```

```{r}
# Parent Endorsement of School (4)
scale_4 <- efa_vars %>%
  select(q54_p1:q57_p1)

mvn(scale_4, subset = NULL, mvnTest = "hz", univariateTest = "AD", univariatePlot = "histogram")

describe(scale_4)
```

```{r}
plots <- split.default(scale_4, names(scale_4)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots
```


# issue of sparseness
```{r}
#contingency tables? 
```


--------------------------
## EFA decisions 
--------------------------

# Homework Involvement (17)
```{r}
# Homework Involvement (17)
scale_7 <- efa_vars %>%
  select(q82_p1:q98_p1)

# Poly corr matrix
poly_scale_7 <- polychoric(scale_7)
poly_scale_7_mat <- data.frame(poly_scale_7$rho)

# scree plot
scree(poly_scale_7_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_7, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
#removing 82, 83, 92
scale_7.1 <- efa_vars %>%
  select(q84_p1:q91_p1, q93_p1:q98_p1)

# PARALLEL ANALYSIS - Homework Involvement (17)
fa.parallel(scale_7.1, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # parrallel analysis suggest 4 factors

# 4 factors
fa(scale_7.1, nfactors = 4, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly")

# 3 factors
fa(scale_7.1, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly")
```

```{r}
#Reliability: Homework Involvement (17)
scale_7.1_fa_1 <- efa_vars %>%
  select(q86_p1:q89_p1, q94_p1, q96_p1, q97_p1)

alpha(scale_7.1_fa_1) # 0.78

scale_7.1_fa_2 <- efa_vars %>%
  select(q84_p1, q85_p1, q93_p1, q95_p1)

alpha(scale_7.1_fa_2) # 0.70 (0.77 if removing 95)

scale_7.1_fa_3 <- efa_vars %>%
  select(q90_p1, q91_p1, q98_p1) 

alpha(scale_7.1_fa_3) # 0.59
```

# Monitoring (5)
```{r}
#Monitoring (5)
scale_10 <- efa_vars %>%
  select(q137_p1, q139_p1, q140_p1, q143_p1, q144_p1)

# Poly corr matrix
poly_scale_10 <- polychoric(scale_10)
poly_scale_10_mat <- data.frame(poly_scale_10$rho)

# scree plot
scree(poly_scale_10_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_10, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
#Reliability: Monitoring (5)

alpha(scale_10) # 0.62
```

# Appropriate Discipline (7) <<<<< ultra-Heywood case>>>>>>>
```{r}
#Appropriate Discipline (7)
scale_9 <- efa_vars %>%
  select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1)

# Poly corr matrix
poly_scale_9 <- polychoric(scale_9)
poly_scale_9_mat <- data.frame(poly_scale_9$rho)

# scree plot
scree(poly_scale_9_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_9, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
# Appropriate Discipline EFA iterations 

# iteration 1
scale_9.1 <- efa_vars %>%
  select(q129_p1:q131_p1, q133_p1, q134_p1, q136_p1)

fa(scale_9.1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # item 129 now appears as heywood

# iteration 2
scale_9.2 <- efa_vars %>%
  select(q130_p1, q131_p1, q133_p1, q134_p1, q136_p1)

fa(scale_9.2, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # no more heywood

poly_scale_9.2 <- polychoric(scale_9.2)
poly_scale_9.2_mat <- data.frame(poly_scale_9.2$rho)

# scree plot
scree(poly_scale_9.2_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# PARALLEL ANALYSIS - Appropriate discipline (7)
fa.parallel(scale_9.2, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5)

# 2 factors (JUST TO CHECK)
# fa(scale_9.2, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # first factor made of just one item and heywood case

# iteration 3
scale_9.3 <- efa_vars %>%
  select(q131_p1, q133_p1, q136_p1)

fa(scale_9.3, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
# Appropriate Discipline reliability 
scale_9.3 <- efa_vars %>%
  select(q131_p1, q133_p1, q136_p1)

alpha(scale_9.3) # 0.50 NOT GOOD

# just to check alpha with the 5 items:
scale_9.2 <- efa_vars %>%
  select(q130_p1, q131_p1, q133_p1, q134_p1, q136_p1)

alpha(scale_9.2) # 0.41 even worse! 
```

```{r}
#Appropriate Discipline univariate analysis

# d2 %>% #before reverse scoring
#   select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1) %>%
#   mutate(q128_p1 = as.factor(q128_p1),
#          q129_p1 = as.factor(q129_p1),
#          q130_p1 = as.factor(q130_p1),
#          q131_p1 = as.factor(q131_p1),# no one fully endorsed yelling
#          q133_p1 = as.factor(q133_p1),# 4 endorsed quiting 
#          q134_p1 = as.factor(q134_p1),#8 endorsed not following
#          q136_p1 = as.factor(q136_p1)) %>%
#   summary()
```

```{r}
#Appropriate Discipline univariate analysis

# efa_vars %>% #after reverse scoring
#   select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1) %>%
#   mutate(q128_p1 = as.factor(q128_p1),
#          q129_p1 = as.factor(q129_p1),
#          q130_p1 = as.factor(q130_p1),
#          q131_p1 = as.factor(q131_p1),
#          q133_p1 = as.factor(q133_p1),
#          q134_p1 = as.factor(q134_p1),
#          q136_p1 = as.factor(q136_p1)) %>%
#   summary()

```


# Structure at home (8)
```{r}
# Structure at home (8)
scale_1 <- efa_vars %>%
  select(q23_p1:q30_p1)

# Poly corr matrix
poly_scale_1 <- polychoric(scale_1)
poly_scale_1_mat <- data.frame(poly_scale_1$rho)

# scree plot
scree(poly_scale_1_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly", sort = TRUE)
```


```{r}
#Reliability: Structure at home (8)

alpha(scale_1) # 0.82
```

# Parent-Child Conversations About School (14)
```{r}
#Parent-Child Conversations About School (14)
scale_6 <- efa_vars %>%
  select(q68_p1:q81_p1)

# Poly corr matrix
poly_scale_6 <- polychoric(scale_6)
poly_scale_6_mat <- data.frame(poly_scale_6$rho)

# scree plot
scree(poly_scale_6_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_6, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
# PARALLEL ANALYSIS Parent-Child Conversations
fa.parallel(scale_6, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # parrallel analysis suggest 3 factors

# 3 factors - iteration 2
fa(scale_6, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # item 74 cross loaded in factor 1 and 2

# iteration 3
scale_6.1 <- efa_vars %>%
  select(q68_p1:q73_p1, q75_p1:q81_p1)

# 3 factors - # iteration 3
fa(scale_6.1, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # item 72 cross loaded in factor 2 and 3

# iteration 4
scale_6.2 <- efa_vars %>%
  select(q68_p1:q71_p1, q73_p1, q75_p1:q81_p1)

# 3 factors - # iteration 4
fa(scale_6.2, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") 
```

```{r}
#Reliability: Parent-Child Conversations About School (14)

#factor 3
scale_6.fa_3 <- efa_vars %>%
  select(q68_p1:q71_p1)

alpha(scale_6.fa_3) # 0.81

#factor 2
scale_6.fa_2 <- efa_vars %>%
  select(q73_p1, q75_p1, q80_p1, q81_p1)

alpha(scale_6.fa_2) # 0.78

#factor 1
scale_6.fa_1 <- efa_vars %>%
  select(q76_p1:q79_p1) 

alpha(scale_6.fa_1) # 0.85
```

# School-based involvement (10)
```{r}
# School-based involvement (10)
scale_2 <- efa_vars %>%
  select(q31_p1:q40_p1)

# Poly corr matrix
poly_scale_2 <- polychoric(scale_2)
poly_scale_2_mat <- data.frame(poly_scale_2$rho)

# scree plot
scree(poly_scale_2_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE) # a little ambiguous

# EFA
fa(scale_2, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```

```{r}
# PARALLEL ANALYSIS School-based involvement 
fa.parallel(scale_2, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5)
# suggests 3 factors, but a warning about ultra heywood case

# 3 factors
fa(scale_2, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # factor 3 barely above eigenvalue >1 and crossloading items

# 2 factors
fa(scale_2, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # q35_p1 cross-loaded


scale_2.1 <- efa_vars %>%
  select(q31_p1:q34_p1, q36_p1:q40_p1)

# 2 factors
fa(scale_2.1, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly")
```

```{r}
#Reliability: School-based involvement 
scale_2.1_fa_1 <- efa_vars %>%
  select(q31_p1:q34_p1)

alpha(scale_2.1_fa_1) # 0.85

scale_2.1_fa_2 <- efa_vars %>%
  select(q36_p1:q40_p1)

alpha(scale_2.1_fa_2) # 0.82
```


##### Relational approach #####

# Parent Belongingness in School (5)
```{r}
# Parent Belongingness in School (5)
scale_3 <- efa_vars %>%
  select(q47_p1, q48_p1, q51_p1, q52_p1, q53_p1)

# Poly corr matrix
poly_scale_3 <- polychoric(scale_3)
poly_scale_3_mat <- data.frame(poly_scale_3$rho)

# scree plot
scree(poly_scale_3_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_3, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```


```{r}
#reliability parent Belongingness in School (5)
alpha(scale_3) # 0.72
```

# Parent Endorsement of School (4) <<< ultra-Heywood case>>>
```{r}
# Parent Endorsement of School (4)
scale_4 <- efa_vars %>%
  select(q54_p1:q57_p1)

# Poly corr matrix
poly_scale_4 <- polychoric(scale_4)
poly_scale_4_mat <- data.frame(poly_scale_4$rho)

# scree plot
scree(poly_scale_4_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA 
fa(scale_4, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")

alpha(scale_4) #.88
```

```{r}
#univariate response frequencies - Parent Endorsement of School (4)
# scale_4 %>%
#   mutate(q54_p1 = as.factor(q54_p1),
#          q55_p1 = as.factor(q55_p1),
#          q56_p1 = as.factor(q56_p1),
#          q57_p1 = as.factor(q57_p1)) %>%
#   summary()
```


```{r}
### -----Parent Endorsement of School (3)----- ###

# EFA without q55_p1 = bec it had a negative u2 and a factor loading of 1
scale_4.1 <- efa_vars %>%
  select(q54_p1, q56_p1, q57_p1)

fa(scale_4.1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")

scree(scale_4.1,factors=TRUE,pc=FALSE,main="Scree plt",hline=NULL,add=FALSE)

alpha(scale_4.1) #.80
```

# Parent’s Value and Support of Education (6) <<<#matrix not positive definitive>>>
```{r}
#Parent’s Value and Support of Education (6)
scale_8 <- efa_vars %>%
  select(q105_p1:q110_p1)

# Poly corr matrix
poly_scale_8 <- polychoric(scale_8)
poly_scale_8_mat <- data.frame(poly_scale_8$rho)

# scree plot
scree(poly_scale_8_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_8, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```


```{r}
#Parent’s Value and Support of Education (6)
fa.parallel(scale_8, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # suggest 1 factor

```

```{r}
# RELIABILITY Parent’s Value and Support of Education (6)

alpha(scale_8) # .91

# scale_8 %>%
#   mutate(q105_p1 = as.factor(q105_p1),
#          q106_p1 = as.factor(q106_p1),
#          q107_p1 = as.factor(q107_p1),
#          q108_p1 = as.factor(q108_p1),
#          q109_p1 = as.factor(q109_p1),
#          q110_p1 = as.factor(q110_p1)) %>%
#   summary()
```

```{r}
# Parent’s Value and Support of Education (6)
# plots3 <- split.default(scale_8, names(scale_8)) %>% 
#   map(., setNames, nm = "var") %>% 
#   map(., rownames_to_column) %>%
#   imap(., ~ {
#     ggplot(.x, aes(var)) + 
#       geom_bar() +
#       labs(title = .y)
#     })
# 
# plots3
```


# Parent-Teacher Relationship (4) <<< ultra-Heywood case>>>
```{r}
# Parent-Teacher Relationship (4) 
scale_5 <- efa_vars %>%
  select(q64_p1:q67_p1)

# Poly corr matrix
poly_scale_5 <- polychoric(scale_5)
poly_scale_5_mat <- data.frame(poly_scale_5$rho)

# scree plot
scree(poly_scale_5_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_5, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")

alpha(scale_5) #.87
```


```{r}
### -----Parent-Teacher Relationship (4) ----- ###

# EFA without q66_p1 = bec it had a negative u2 and a factor loading of 1
scale_5.1 <- efa_vars %>%
  select(q64_p1, q65_p1, q67_p1)

fa(scale_5.1, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # another ultra-heywood, item 67

scree(scale_5.1,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

alpha(scale_5.1) #.80

# EFA without q67_p1 = bec it had a factor loading of 0.99
scale_5.2 <- efa_vars %>%
  select(q64_p1, q65_p1) # not reasonable a 2 item scale

fa(scale_5.2, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")

scree(scale_5.2,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

alpha(scale_5.2)#.67
```


# Family-School Communication (6)
```{r}
#Family-School Communication (6)
scale_11 <- efa_vars %>%
  select(q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1)

# Poly corr matrix
poly_scale_11 <- polychoric(scale_11)
poly_scale_11_mat <- data.frame(poly_scale_11$rho)

# scree plot
scree(poly_scale_11_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_11, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```
```{r}
#Family-School Communication (4)
scale_11.2 <- efa_vars %>%
  select(q41_p1, q43_p1, q50_p1, q62_p1)

# EFA
fa(scale_11.2, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```


# Problem Solving with Educators (4)
```{r}
#Problem Solving with Educators (4)
scale_12 <- efa_vars %>%
  select(q44_p1, q58_p1, q63_p1, q126_p1)

# Poly corr matrix
poly_scale_12 <- polychoric(scale_12)
poly_scale_12_mat <- data.frame(poly_scale_12$rho)

# scree plot
scree(poly_scale_12_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_12, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```


```{r}
#Problem Solving with Educators (4) 
fa.parallel(scale_12, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # suggest 2 factors, but one appears to be an eigenvalue less than 1

# EFA 2 factors
fa(scale_12, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # with 2 factors shows ultra-heywood case, also would be each factor with just 2 items
```


```{r}
#Reliability: Problem Solving with Educators (4) 

alpha(scale_12) # 0.71; if removing items 126 would be .79
```

# Combined scale: Parent-Teacher Relationship (4), Family-School Communication (6), Problem Solving with Educators (4)

q64_p1, q65_p1, q66_p1, q67_p1 --> parent-teacher rel

q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1 --> communication

q44_p1, q58_p1, q63_p1, q126_p1 --> problem solving

```{r}
# rel combined
scale_comb <- efa_vars %>%
  select(q18_p1, q19_p1, q41_p1, q43_p1, q44_p1, q50_p1, q58_p1, q62_p1, q63_p1, q64_p1, q65_p1, q66_p1, q67_p1, q126_p1) # items 18 and 19 loading less than .30

scale_comb <- efa_vars %>%
  select(q41_p1, q43_p1, q44_p1, q50_p1, q58_p1, q62_p1, q63_p1, q64_p1, q65_p1, q66_p1, q67_p1, q126_p1)

# Poly corr matrix
poly_scale_comb <- polychoric(scale_comb)
poly_scale_comb_mat <- data.frame(poly_scale_comb$rho)

# scree plot
scree(poly_scale_comb_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA rel combined
fa(scale_comb, n.obs = NA, rotate = "none", fm = "uls", cor = "poly") # matrix not positive definite, but looks good
```


```{r}
# rel combined
fa.parallel(scale_comb, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # parallel analysis suggest 3 factors, matrix not positive,  ultra heywood 

# 3 factors 
fa(scale_comb, nfactors = 3, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly") # 66 was Heywood, other 3 items were crossloading
```

```{r}
# rel combined - EFA 2 factors
fa(scale_comb, nfactors = 2, n.obs = NA, rotate = "quartimin", fm = "uls", cor = "poly")
```

```{r}
scale_comb_fa1 <- efa_vars %>%
  select(q41_p1, q58_p1, q62_p1, q63_p1, q64_p1, q65_p1, q66_p1, q67_p1)

alpha(scale_comb_fa1) #.90

scale_comb_fa2 <- efa_vars %>%
  select(q43_p1, q44_p1, q50_p1, q126_p1)

alpha(scale_comb_fa2) #.78
```




# OUTCOME: Students’ School Engagement (9)
```{r}
#Students’ School Engagement (9)
scale_13 <- efa_vars %>%
  select(q83_y1:q91_y1)

# Poly corr matrix
poly_scale_13 <- polychoric(scale_13)
poly_scale_13_mat <- data.frame(poly_scale_13$rho)

# scree plot
scree(poly_scale_13_mat,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

# EFA
fa(scale_13, n.obs = NA, rotate = "none", fm = "uls", cor = "poly")
```
```{r}
fa.parallel(scale_13, n.obs=NULL, fm="uls", fa="fa", nfactors=1, main="Parallel Analysis Scree Plots", n.iter=20, error.bars=FALSE, se.bars=FALSE, SMC=FALSE, ylabel=NULL, show.legend=TRUE, sim=TRUE, quant=.95, cor="poly", use="pairwise", plot=TRUE, correct=.5) # suggest 1 factors

alpha(scale_13) # .72, if removing item 84 goes up to .80 -- EFA sowed factor loading of 0.07
```

-------------------------------------------------
Excerpts
-------------------------------------------------
Determining the number of factors in EFA:

"A number of analytical processes have been used to determine
the number of factors to retain from a list of items, and it is
beyond the scope of this paper to describe all of them. For
scale development, commonly available methods to determine
the number of factors to retain include a scree plot (85), the
variance explained by the factor model, and the pattern of factor loadings (2). Where feasible, researchers could also assess the optimal number of factors to be drawn fromthe list of items using either parallel analysis (86), minimum average partial procedure (87), or the Hull method (88, 89)." (Boateng et al., 2018)

DD also suggested parallewl analysis... Maybe use it when in doubt? For HW involvement? 

---------------------------------------------
Psych package info:
" For those who like SPSS type output, the measure of factoring adequacy known as the Kaiser-Meyer-Olkin KMO test may be found from the correlation matrix or data matrix using the KMO function. Similarly, the Bartlett’s test of Sphericity may be found using the cortest.bartlett function"


Model fit indices:

"RMSEA is an absolute fit index, in that it assesses how far a hypothesized model is from a perfect model. On the contrary, CFI and TLI are incremental fit indices that compare the fit of a hypothesized model with that of a baseline model (i.e., a model with the worst fit)" (Xia & Yang, p. 309)

Hu and Bentler (1999) suggested relatively good model–data fit:
RMSEA smaller than .06 
CFI and TLI larger than .95 

But these estimates are for continuous data, using normal-theory maximum likelihood (ML). 

Conclusion from (Xia & Yang, p. 421)
"Given that the DWLS and ULS fit indices tend to show a better model–data fit evaluation than do ML fit indices when the same misspecified model is analyzed, we argue that surpassing a set of cutoff values should not serve as the only justification for the acceptance of a model. It would be more appropriate to consider RMSEA, CFI, and TLI as diagnostic tools for model improvement." 

-----
alpha internal consistencies benchmarks
.00 to .69 = Poor reliability  
.70 to .79 = Fair reliability  
.80 to .89 = Good reliability  
.90 to .99 = Excellent/Strong reliability  

---- Qs ----
Q: Are model fit indices used in EFA? Still not super clear. DD said will send some info.

reliability --- alpha -- can be done with ordinal scales?

DD: polychoric may be robust to non-normality


test to look at input hsquared


for heywood cases, say that porb measures are suspect and may need to be improved

######### EXPLORING UNIVARIATE IN HEYWOOD CASES ##############

Endorsement:

Como madre/padre en esta escuela, estoy segura/o de que…

54. … esta escuela es un buen lugar para mi joven. 
56. … la gente en la escuela de mi joven es confiable.
57. … la escuela de mi joven hace un buen trabajo preparando a      los jóvenes para sus futuros.

59. … los maestros de mi joven se preocupan por ella/el.
60. … maestros y administradores trabajan juntos para crear un ambiente seguro y acogedor para todos.

52. …feliz de que mi joven asista a esta escuela.

-------
55. … el personal de la escuela de mi joven está haciendo     cosas buenas por ella/el.
-------


En esta escuela, siento que hay por lo menos un maestro…
64. … que se preocupa por mi joven.
65. … quien está interesado en conocerme.

---------
66. … con quien me siento/a cómodo/a hablando sobre mi joven.
67. … de quien puedo hacer preguntas o hacer sugerencias sobre mi joven.
---------

#ultra-Heywood case
Como madre/padre en esta escuela, estoy segura/o de que…
54. … esta escuela es un buen lugar para mi joven. 
55. … el personal de la escuela de mi joven está haciendo cosas buenas por ella/el.*
56. … la gente en la escuela de mi joven es confiable.
57. … la escuela de mi joven hace un buen trabajo preparando a los jóvenes para sus futuros.

```{r}
# Parent Endorsement of School (4)
scale_4 <- efa_vars %>%
  select(q54_p1:q57_p1)

scale_4 %>%
  mutate(q54_p1 = as.factor(q54_p1),
         q55_p1 = as.factor(q55_p1),
         q56_p1 = as.factor(q56_p1),
         q57_p1 = as.factor(q57_p1)) %>%
  summary()
```

```{r}
plots <- split.default(scale_4, names(scale_4)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots
```

see univariate and check what is the percenatge of responses in each case to provide argumnet that variables are not "varying"
think in discussion which had a really strong factor solution with large variance explained and will i recommend dropping or imporving the measures 

"This outcome highlights the general concern of sparseness, or the tendency of highly skewed items to produce observed bivariate distributions with cell frequencies equaling zero or close to zero,especially with relatively small overall sample size. Sparseness can cause biased polychoric correlation estimates, which in turn leads to inaccurate factor
analysis results" (Flora et al. 2012, p. 18)

#ultra-Heywood case
En esta escuela, siento que hay por lo menos un maestro…
64. … que se preocupa por mi joven.
65. … quien está interesado en conocerme.
66. … con quien me siento/a cómodo/a hablando sobre mi joven.*
67. … de quien puedo hacer preguntas o hacer sugerencias sobre mi joven.*

```{r}
# Parent-Teacher Relationship (4) 
scale_5 <- efa_vars %>%
  select(q64_p1:q67_p1)

scale_5 %>%
  mutate(q64_p1 = as.factor(q64_p1),
         q65_p1 = as.factor(q65_p1),
         q66_p1 = as.factor(q66_p1),
         q67_p1 = as.factor(q67_p1)) %>%
  summary()
```

```{r}
plots2 <- split.default(scale_5, names(scale_5)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots2
```


#ultra-Heywood case

128. En casa, estamos de acuerdo con reglas claras sobre lo que mi joven puede y no puede hacer.
129. Mi joven sabe cómo voy a responder cuando hace algo malo cosas que no me gustan o lo que está en contra las reglas de la casa).
130. Cada vez que mi joven hace algo mal, yo le respondo con una consecuencia específica (por ejemplo, una disciplina específica, quitándole      privilegios, etc.)
131. Cuando mi joven hace algo mal, le grito o le insulto. R
133. Cuando mi joven me desafía al no hacer lo que le pido, yo renuncio. R
134. Cuando mi joven está aprendiendo un nuevo comportamiento (por ejemplo: ser más responsable, estudioso/a u organizado/a), reconozco su        progreso con, por ejemplo, un abrazo, una sonrisa o un pequeño regalo.
136. Cuando le doy una amenaza o advertencia a mi joven, frecuentemente no lo llevo a cabo. R

```{r}
#Appropriate Discipline (7)
scale_9 <- efa_vars %>%
  select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1)

scale_9 %>%
  mutate(q128_p1 = as.factor(q128_p1),
         q129_p1 = as.factor(q129_p1),
         q130_p1 = as.factor(q130_p1),
         q131_p1 = as.factor(q131_p1),
         q133_p1 = as.factor(q133_p1),
         q134_p1 = as.factor(q134_p1),
         q136_p1 = as.factor(q136_p1)) %>%
  summary()
```

```{r}
plots4 <- split.default(scale_9, names(scale_9)) %>% 
  map(., setNames, nm = "var") %>% 
  map(., rownames_to_column) %>%
  imap(., ~ {
    ggplot(.x, aes(var)) + 
      geom_bar() +
      labs(title = .y)
    })

plots4
```

Item 55 and 66 consistently show as ultraheywood cases

item 55 "Como madre/padre en esta escuela, estoy segura/o de que… el personal de la escuela de mi joven está haciendo cosas buenas por ella/el."

item 66 "En esta escuela, siento que hay por lo menos un maestro…… con quien me siento/a cómodo/a hablando sobre mi joven"

```{r}
efa_vars %>%
  select(q55_p1, q66_p1) %>%
  mutate(q55_p1 = as.factor(q55_p1),
         q66_p1 = as.factor(q66_p1)) %>%
  summary()
```
