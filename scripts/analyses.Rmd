---
title: "analyses"
author: "Alejandra Garcia Isaza"
date: "4/5/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rio)
library(here)
library(tidyverse)
library(haven)
library(janitor)
library(knitr)
library(surveytoolbox)
library(sjPlot)
library(kableExtra)
library(psych)
library(sjmisc)

theme_set(theme_minimal())
```

# Loading the dataset
```{r}
d <- read_sav(here("data", "parent_hv1_youth_w1.sav"))
```

# only analysis variables

## id variables
school_id, condition, family_id, participant_id

## scales variables
- Structure at home (8)
select(q23_p1:q30_p1)

- School-Based Involvement (10)
select(q31_p1:q40_p1)

- Parent Belongingness in School (7)
select(q47_p1, q48_p1, q51_p1, q52_p1, q53_p1, q59_p1, q60_p1)

- Parent Endorsement of School (4)
select(q54_p1:q57_p1)

- Parent-Teacher Relationship (4) 
select(q64_p1:q67_p1)

- Parent-Child Conversations About School (14)
select(q68_p1:q81_p1)

- Homework Involvement (17)
select(q82_p1:q98_p1)

- Parent’s Value and Support of Education (6)
select(q105_p1:q110_p1)

- Appropriate Discipline (7)
select(q128_p1:q131_p1, q133_p1, q134_p1, q136_p1)

- Monitoring (5)
select(q137_p1, q139_p1, q140_p1, q143_p1, q144_p1)

- Family-School Communication (6)
select(q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1)

- Problem Solving with Educators (4)
select(q44_p1, q58_p1, q63_p1, q126_p1)

## outcome variable
- Students’ School Engagement (9)
select(q83_y1:q91_y1)

## moderators
- Ed level (1 - 11)
q36_hv1

- ENG comfort in youth school (1 - 5, 77, 99)
q173_3_p1

```{r}
d1 <- d %>%
  select(school_id, condition, family_id, participant_id, q23_p1:q30_p1, q31_p1:q40_p1, q47_p1, q48_p1, q51_p1, q52_p1, q53_p1, q59_p1, q60_p1, q54_p1:q57_p1, q64_p1:q67_p1, q68_p1:q81_p1, q82_p1:q98_p1, q105_p1:q110_p1, q128_p1:q131_p1, q133_p1, q134_p1, q136_p1, q137_p1, q139_p1, q140_p1, q143_p1, q144_p1, q18_p1, q19_p1, q41_p1, q43_p1, q50_p1, q62_p1, q44_p1, q58_p1, q63_p1, q126_p1, q36_hv1, q173_3_p1, q83_y1:q91_y1) # double check this, evaluate missing data 
```
# descriptives check 
```{r}
describe(d1)

# using describe function I identified that missing values in the dataset were -99, 99, 77
```


# recoding missing variables as N/A
```{r include=FALSE}
# recoding missing values as N/A with function

# vector with missing values in dataset
missing_vals <- c(77, 99, -99)

# function that returns true if values in vector are equal to missing_vals. The function takes a vector x, and specified values of missing data
recode_missing <- function(x, missing_vals = c(77, 99, -99)) {
  test <- x %in% missing_vals
  ifelse(test, NA, x)
}

# function that recodes missing values to NA. The function takes a dataframe with variables with missing data, and specified values of missing data
recode_missing_df <- function(df, missing_vals = c(77, 99, -99)) {
  modify(df, ~recode_missing(.x, missing_vals)) # here uses the function created above
}

d2 <- recode_missing_df(d1) # the function strips out variable labels
```
# descriptives check #2
```{r}
describe(d2)

# using describe function I identified that some variables had a lot of missing information:
# q65_p1 = 89/94 responses ("En esta escuela,siento que hay por lo menos un maestro quien está interesado en conocerme")
# q173_3_p1 = 86/94 responses ("¿Qué tan cómodo/ase siente hablando inglés en la ESCUELA de su joven") --> moderator

(sum(is.na(d2))/prod(dim(d2)))*100 # 0.8450984 (this is less than 1% of the data, should I do something about it?)

# Nico's explanation:
#test <- describe(d2)
#(sum(94-test$n))/(94*107)
```

# Data prep: reverse scoring negatively worded items
```{r}
d3 <- d2 %>%
  mutate(q82_p1 = likert_reverse(q82_p1, top = 4, bottom = 1),
         q83_p1 = likert_reverse(q83_p1, top = 4, bottom = 1),
         q131_p1 = likert_reverse(q131_p1, top = 4, bottom = 1),
         q133_p1 = likert_reverse(q133_p1, top = 4, bottom = 1),
         q136_p1 = likert_reverse(q136_p1, top = 4, bottom = 1),
         q84_y1 = likert_reverse(q84_y1, top = 5, bottom = 1),
         q86_y1 = likert_reverse(q86_y1, top = 5, bottom = 1),
         q87_y1 = likert_reverse(q87_y1, top = 5, bottom = 1)) # 
```


# checking assumptions for pearson correlation model
"Departures from normality and linearity are important only because they affect the Pearson product-moment correlation coefficients (r) among measured variables used for computation of EFA results, which, in turn, “can result in misleading EFA findings” (Reise, Waller, & Comrey, 2000, p. 289). Therefore, it is important to investigate and report the distributional properties of the data that might affect the Pearson correlations (Goodwin & Leech, 2006)." (Watkins, 2018, p. 223). 

- Variability
- linearity
- Normality (skew & kurtosis)
- Outliers
- Measurement error: variables with reliabilities > .70 (which computation?)
- Correlation matrix: sizable number of correlations should exceed ±.30 

# dataset with only EFA variables 
```{r}
efa_vars <- d3 %>%
  select(-school_id, -condition, -family_id, -participant_id, -q36_hv1, -q173_3_p1)
```

```{r}
# Structure at home
scale_1 <- efa_vars %>%
  select(q23_p1:q30_p1)

round(cor(scale_1, method = "pearson", use = "complete.obs"), digits = 2) # pearson corr

```

```{r}
poly_scale_1 <- polychoric(scale_1)
# 
# poly_scale_1 <- data.frame(polychoric(scale_1)) # need to create a datafranme with correlation matrix to use it in scree function 
# 
# dim(poly_scale_1)


```

```{r}
poly_scale_1_df <- data.frame(poly_scale_1$rho)
```
```{r}

# not sure of the difference between these two
scree(poly_scale_1_df,factors=TRUE,pc=TRUE,main="Scree plot",hline=NULL,add=FALSE)

scree(poly_scale_1_df,factors=FALSE,pc=TRUE,main="Scree plot",hline=NULL,add=FALSE)

scree(poly_scale_1_df,factors=TRUE,pc=FALSE,main="Scree plot",hline=NULL,add=FALSE)

VSS.scree(poly_scale_1_df, main = "scree plot")
```

```{r}

```


# trying to visualize
```{r}
plot(scale_1) # trying to find a way to visualize several plots at a time

# Not sure how to visualize ordinal scales
# ggplot(scale_1, aes(q23_p1)) +
# geom_histogram(alpha = 0.7) # histograms only for continuous vars

ggplot(scale_1, aes(q23_p1)) +
geom_bar() # to visualize univariate discrete
```

```{r}
 ggplot(scale_1, aes(q23_p1, q24_p1)) +
  geom_count() +
  geom_jitter(h = 2, w = 2)
```



